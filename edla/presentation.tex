\chapter{Présentation générale}

\section{Présentation du projet}
Aujourd'hui, détecter les points des articulations du corps humain 
est une technique courante, grâce à certains périphériques tels que la 
Kinect. Les points des articulations du corps forment le squelette 3D. 
Cependant, les squelettes 3D ne sont en général pas assez riche en 
informations concernant les points des articulations des mains.\\

Pourtant les mains sont habiles et nous pouvons faire de nombreux 
mouvements, plus ou moins complexes et rapides, avec elles. De plus en 
plus d'applications nécessitent des IHM plus précises et plus 
naturelles. Utiliser ses mains pour contrôler, interagir et communiquer 
avec un ordinateur, devient très intéressant. Ce niveau de 
précision peut être utile dans divers domaines :
\begin{itemize}
  \item simulation médicale.
  \item modélisation et CAO\footnote{Conception Assisté par Ordinateur}.
  \item manipulation d'objets 3D virtuels.
  \item jeux vidéo.\\
\end{itemize}

Le projet \og Hand Kinect \fg \ consiste à extraire depuis une caméra Kinect 2, 
les points des articulations des mains, pour cela nous étudions plusieurs 
méthodes réalisées jusqu'à maintenant. Ainsi, l'assemblage de ces points 
nous permet d'obtenir le squelette 3D complet de la personne devant la 
Kinect.\\

\begin{figure}[H]
  \label{jointPoint}
  \begin{center}
    \includegraphics[width=350px]{images/joint_detection.png}
    \caption{Détection des articulations des mains}
  \end{center}
\end{figure}

Ensuite, nous souhaitons animer un modèle 3D, qui peut être un modèle 
d'humain, de robot ou bien de créature. Les mouvements de ce modèle 
doivent suivre les points du squelette préalablement détectés, de 
manière cohérente par rapport aux mouvements de la personne devant la 
Kinect. Nous utilisons Unity3D, pour cette partie de 
modélisation.\\

Unity3D est un moteur de jeu qui permet de développer rapidement des 
environnements et applications 3D. Il est facile d'obtenir des 
applications compatibles sur de nombreuses plateformes. Ce moteur 
propose également une licence gratuite assez complète.\\

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=350px]{images/Unity3D.jpg}
    \caption{Interface de Unity3D}
  \end{center}
\end{figure}

%TODO Modifier la partie sur la modélisation 3D
Dans le cadre de ce projet, nous sommes amenés à rédiger un état de
l'art. Cette première partie nous permet de synthétiser et sélectionner 
les solutions. Notre objectif étant de détecter la main d'une personne 
et ses articulations, afin d'animer en 3D les mouvements de la main de 
cette personne. Cela doit être réalisable en temps réel et à partir d'une caméra nous 
fournissant une image RGB et une image contenant l'information de 
profondeur de la scène filmée.\\

\section{Contexte}
La réalisation de ce projet se fait avec l'équipe 3D 
SAM\footnote{Modeling and Analysis of Static and Dynamic Shapes}. 
Cette équipe fait partie du laboratoire CRIStAL\footnote{Centre de Recherche 
en Informatique, Signal et Automatique de Lille}. Ce centre est le 
nouveau pôle de recherche qui regroupe les laboratoires d'informatique, 
signal et automatique de Lille.\\

L'équipe 3D SAM est basée à l'école d'ingénieur Télécom Lille. 
Cette équipe conçoit de nouveaux outils et méthodes d'analyse des 
formes des objets 3D statiques et dynamiques. Ils travaillent sur 
l'analyse de formes des objets 3D et la modélisation des variations 
des formes dans des vidéos 3D.

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=300px]{images/accueil-illus.jpg}
    \caption{Exemples de travaux de l'équipe 3D SAM}
  \end{center}
\end{figure}

%TODO pour le module -> vu l'état de l'art on considere qu'on la pas tout de suite
Le projet \og Hand Kinect \fg est un nouveau projet proposé par 
l'équipe.
Pour sa réalisation, nous disposons d'une caméra Kinect 2. 
Pour les représentations et animations 3D, il nous faut un environnement 
de modélisation. Nous utilisons Unity3D comme montré précédemment. 
Nous disposons également, d'un module nous permettant d'extraire les 
points des articulations de la main.

\section{Problèmatique}
D'abord, la Kinect 2 peut déjà suivre six personnes à la fois. Elle 
détecte un squelette de vingt-six points (voir Fig. 
\ref{fig:skeleton_kinect2} et \ref{fig:kinect1vs2}). Cependant, les 
mains sont représentées seulement par 4 points, qui sont le centre du
poignet, le centre de la main, le pouce et le bout du majeur. C'est une 
amélioration par rapport à la Kinect 1, qui ne détectait que le poignet 
et le centre de la main.\\

D'autres outils permettent de détecter les mains des utilisateurs. Par 
exemple le Leap Motion détecte les articulations des mains. Néanmoins,
ce capteur est limité, car il faut garder les mains proches du capteur.
La portée et le champ de détection de ce dispositif restent restreint. 
Leap Motion ne permet pas de détecter le squelette complet d'une personne.
Il permet cependant une plus grande précision et une plus grande stabilité
que la Kinect dans la détection des articulations de la main.\\

À partir de ces constats, nous pouvons formuler la problématique 
suivante. Puisque, 
les mains sont très habiles, il peut être difficile de détecter leurs 
articulations dans des positions contraignantes. En supplément, les 
problèmes liés à la luminosité sont récurrents, il est souhaitable 
d'utiliser des techniques robustes et invariantes à la luminosité, 
mais qui restent efficaces. De plus, il existe encore peu de méthodes 
permettant de détecter la pose et les articulations par caméra, et 
qui permettraient de retrouver l'ensemble du squelette humain. Enfin, 
la modélisation de la main dans la scène 3D doit être fidèle à 
la main de l'utilisateur pour plus de précision et de réalisme.

%comment réaliser ce projet, avec quoi + résultat attendu
\section{Objectif}
%TODO objectif de l'état de l'art
%Le premier objectif est la détection des points des articulations 
%des mains. Pour cela, nous utilisons le module fournit par nos 
%tuteurs. Ainsi, il faut extraire les points des articulation des 
%mains, afin de les rendre utilisable dans Unity3D.\\
%
%En suite, un second objectif consiste modéliser les points des 
%articulations des mains, dans le but d'obtenir une première 
%visualisation simple. Il faut également pouvoir récupérer le 
%squelette calculer par la Kinect 2.\\
%
%Le troisième objectif est de déterminer quelque type de modèle 3D, 
%nous allons utiliser avec de représenter la main. Et, déterminer 
%si il faut segmenter les modèles de mains pour notre application.\\
%
%Après cela, le quatrième objectif est de faire correspondre un 
%modèle 3D de main avec les points des articulations détectés. Un 
%script C\# pour Unity3D peut permettre d'effectuer cette 
%correspondance.\\
%
%Enfin le dernier objectif est de rassembler les points des articulations 
%des mains détecté et les points du squelette calculés par la Kinect 2. 
%Afin de animer un personnage virtuel 3D dont les mouvements sont guidés 
%par les gestes de l'utilisateur devant la Kinect 2. 

Dans un premier temps, le but de ce rapport est d'appréhender les 
différentes méthodes existantes sur la détection des mains, leurs 
articulations et la reconnaissance de la pose des mains. Nous souhaitons
également comprendre les principes utilisés lors de l'animation 3D de
celles-ci.\\ 
%Mais aussi de 
%comprendre les principes utilisés pour la modélisation en 3D des 
%mains.\\ 

Étudier les techniques de détection des mains et leurs articulations, 
a pour objectif de bien cerner les méthodes qui peuvent être utilisées 
par le module. Celui-ci fournit les positions spatiales des 
articulations des mains.\\

Ensuite, le but de l'étude des techniques d'animation des mains en 
3D est de pouvoir comprendre et utiliser efficacement les techniques pour animer les mains de façon naturelle dans Unity3D.\\

Le dernier objectif de cette première partie, est de faire une 
planification des tâches à effectuer. Ceci permet de s'organiser et 
de voir si les objectifs futurs sont réalisables dans les délais 
impartis.\\  


\section{Présentation de la Kinect 2}
La Kinect 2 de Microsoft possède une caméra couleur en mode YUV de 1920x1080 pixels.
YUV est une combinaison particulière d'informations permettant de restituer la couleur, comme RGB ou HSP.
Cette combinaison aussi appelée YCbCr, avec Y la luminance, U/Cb la composante bleue sans luminance et V/Cr la composante rouge sans luminance.
En plus de sa caméra couleur, elle possède 3 diffuseurs de rayonnements infrarouges couplés à une caméra infrarouge qui servent à acquérir une carte de profondeur.
Les autres fonctionnalités ne nous intéresseront pas pour résoudre notre problématique.\\

\begin{figure}[H]
 \center
 \includegraphics[width=250px]{images/kinect-v2.png}
 \caption{Caméra Kinect 2}
\end{figure}

On récupère donc de Kinect les données brutes suivantes : 
\begin{itemize}
 \item un flux vidéo couleur en YUV
 \item un flux vidéo d'images de profondeur Fig. \ref{fig:depthMap}
\end{itemize}

Ces deux flux peuvent servir à détecter la main (méthodes expliquées dans la partie état de l'art).
Le SDK de la Kinect fournit des informations déjà traitées, 
par exemple pour notre projet, les jointures du poignet, du centre de la main, du sommet du pouce et du sommet du majeur.

\begin{figure}[H]
\center
\includegraphics[width=250px]{images/kinec2_skel.png}
\caption{Squelette de l'utilisateur détecté par la Kinect 2}
\label{fig:skeleton_kinect2}
\end{figure}

\subsection{Différences entre Kinect V1 et Kinect V2}

Comme on peut la voir dans l'image ci-dessous, la Kinect 2 est une amélioration de tous les aspects de la Kinect précédente.\\

Les améliorations qui nous intéressent pour le projet sont : 
\begin{itemize}
 \item L'augmentation de la résolution de la caméra de profondeur, qui apporte une précision plus importante, mais cause un problème de performance : plus de pixels à traiter.
 \item L'augmentation des champs de vision horizontaux et verticaux
 \item Le plus important : l'augmentation du nombre de points détectés, principalement l'ajout de 2 points au niveau de la main
\end{itemize}

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=350px]{images/kinect-v2-introduction-and-tutorial-8-638.jpg}
    \caption{Différence entre Kinect V1 et Kinect V2}
    \label{fig:kinect1vs2}
  \end{center}
\end{figure}

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=350px]{images/kyle_kinect.jpg}
    \caption{Depth map 3D de la Kinect 2}
    \label{fig:depthMap}
  \end{center}
\end{figure}

%présentation du materiel + image materiel
%présentation des données brut
%présentation du sdk + image squelette
