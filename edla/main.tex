\documentclass{article}

\usepackage[francais]{babel}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{apalike}
\usepackage{setspace}
\usepackage{cite}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{multicol}
\usepackage{setspace}


% code color

\definecolor{ligthyellow}{RGB}{250,247,220}
\definecolor{darkblue}{RGB}{5,10,85}
\definecolor{ligthblue}{RGB}{1,147,128}
\definecolor{darkgreen}{RGB}{8,120,51}
\definecolor{darkred}{RGB}{160,0,0}
\definecolor{univ}{RGB}{177,23,119}
\definecolor{univmodif}{RGB}{148,74,120}
\definecolor{mygray}{RGB}{100,100,100}


\title{État de l'art sur la détection, le suivi de la main et animation de celle-ci dans une scène 3D.}

\author{
Alexis Robache \\
\texttt{robache.alexis@gmail.com} \\
\and
Elliot Vanegue\\
\texttt{elliot.vanegue@gmail.com} \\
\and
Gaëtan Deflandre\\
\texttt{gaetan.deflandre@gmail.com} \\
}


%TODO modifier les référence pour que cela afficher des numéros -> citation beaucoup trop longue



\begin{document}

%% PAGE DE GARDE
%% =============

\begin{multicols}{2}  

    \textbf{Auteurs:}
    \begin{itemize}
      \item Alexis ROBACHE
      \item Elliot VANEGUE
      \item Gaëtan DEFLANDRE
    \end{itemize}
    
    \textbf{Encadrants:}\\
    \begin{itemize}
      \item Hazem WANNOUS
      \item Jean-Philippe VANDEBORRE 
    \end{itemize}

\end{multicols}

\vspace{3cm}

 \begin{flushright}
  \begin{spacing}{1.6}
    \textbf{
      {\Large État de l'art sur la détection, le suivi de la main et 
        animation de celle-ci dans une scène 3D}
    }
  \end{spacing}
  \hrule
  \vspace{0.2cm}
  \textit{
  	{\large\textcolor{mygray}{État de l'art, projet de fin de Master IVI}}
  }
\end{flushright}

\vspace{3cm}

\begin{center}
  \includegraphics[height=3.5cm]{images/logoLILLE1.jpg}
  \hfill
  % logo équipe
  %\includegraphics[height=3.5cm]{image/}
  \vspace{3cm}

  \vspace{1cm}
  {\large\textbf{Octobre 2015 à Février 2016}}
\end{center}



\newpage


%% TABLE DES MATIERES
%% ==================

\tableofcontents

\newpage



%% RESUME
%% ======

%% vraiment à mettre pour un edla ?

%\begin{abstract}
%TODO
%\end{abstract}

%\newpage



%% INTRO
%% =====

\input{intro.tex}

\newpage



%% DEVELOPPEMENT
%% =============

\section{Etat de l'art}

\subsection{Différents type de données}
%TODO on ne doit pas utiliser le leap motion pour le projet
Pour réaliser notre projet : animer un modèle de main en se basant sur les mouvements de la main de l'utilisateur, nous avons à disposition une Kinect 2 et un LeapMotion. Pour commencer notre état de l'art, nous allons voir quelles données peuvent être récupérées par ces outils et quels autres moyens auraient pu être utilisés pour réaliser ce projet.

Une liste non exhaustive des périphériques et des données utile qu'ils fournissent : 
\begin{itemize}
\item Kinect et Kinect 2 de Microsoft, fournissent en données brutes une image RGB ainsi qu'une image de profondeur. En utilisant le SDK fournis, on dispose en plus nombreux outils parmi lesquels une détection du squelette et pour Kinect 2 une abstraction de la main avec 3 points détectés : le centre du poignet, le sommet de pouce et le sommet du majeur. 
\item LeapMotion et LeapMotion 2, fournissent en données brutes une image de profondeur plus détaillée mais sur une zone plus restreinte. Avec le SDK, on a accès à 
%% TODO se renseigner sur le SDK et la technologie LeapMotion
\item RealSense 
\end{itemize}

Les données en RGB peuvent être utiliser avec des accessoires pour utilisées pour simplifier la détection des points de la main. \cite{wang2009real} 

Elles peuvent également être associées avec des données de profondeur pour améliorer la détection et gérer les cas de superposition \cite{van2011combining}

\subsection{Modélisation de la main}
Pour mieux visualiser les actions réalisées par la main de l'utilisateur, il est nécessaire d'avoir
un modèle de la main qui soit réaliste et précis par rapport à la réalité. Pour cela, nous avons besoin d'un
mesh d'une main modèle. La méthode utilisé par \cite{export:217428} permet en utilisant l'algorithme
ICP\footnote{Iterated Closest Point} \cite{zhang:inria-00074899} de modifier le mesh de la main afin
que les points de celui-ci aient une distance moins importante avec le nuage de point fourni pas la 
caméra. La méthode de \cite{export:217428} permet également d'adapter le squelette du modèle de la 
main, ce qui permet d'avoir une précision plus importante lors de l'utilisation de l'application.
Cette méthode se repose sur le calcul de la fonction énergie.

%comprehension elliot
%Pour cette méthode il faut utiliser un model de base de la main, puis il faut récupérer un nuage de 
%point. Ensuite avec un systeme d'énergie il faut rapprocher les points du maillage de base avec les 
%point du nuage de point -> ICP-style

\subsection{Détection de la main}
\subsubsection{Détection de la ROI}
Pour réaliser la détection de la main, il faut dans un premier temps déterminer une ROI\footnote{Region Of Interest}
autour ce celle-ci. Cette première étape a été expliqué dans \cite{export:238453}, où les auteurs utilise un classifieur
qui se repose sur la méthode développé dans \cite{export:145347}.

% La méthode de \cite{export:238453} permet de détecter la main de l'utilisateur à partir d'une
% région d'intérêt autour de la main. Il est possible de ne pas avoir deux base d'apprendissage comme
% il est proposé dans cette méthode, mais le SDK de la Kinect 2 afin de ne pas devoir prendre en 
% compte la rotation de la main de l'utilisateur.

%comprehension elliot
% \begin{itemize}
% \item utilisation de données d'apprentissage pour déterminer des postures de main
% \item besoin d'une détermination global de la position et de l'orientation de la main -> kinect doit la fournir dans notre cas
% \item notion de golden energy -> a voir
% \item la golden energy permet d'avoir une plus grande précision sur le score permettant
% de déterminer la posture de la main
% \item a partir de la position global de la main -> creation d'une ROI raisonnable. Pour moi cette ROI est déjà
% calculé dans la librairie de kinect
% \item pour supprimer ce qui ne correspond pas à la main -> projection des vertex sur la depthmap? avec
% transformation de la distance 3D?
% \item la golden energy est calculé à partir de la depthmap et d'une image couleur? etrange au debut il dise qu'il
% utilise que la depthmap (dernier paragraphe de l'intro)
% \item deux couches d'apprentissage : une pour la rotation de la main et une seconde pour tout le reste comme
% la position des doigts
% \item distance de fonctionnement 0.5 - 4.5
% \end{itemize}

% Les questions pour l'équipe
% \begin{itemize}
% \item plus de précision sur la golden energy
% \item aura-t-on des données sur les postures de la main ou devra t on écrire un programme d'apprentissage
% \item le model de la va t elle contenir le squelette avec le skinning
% \end{itemize}


\subsection{Evaluation des solutions envisagées}

\newpage



%% CONCLUSION
%% ==========

\section{Conclusion}

\newpage



%% REFERENCES
%% ==========

\bibliographystyle{ieeetr} % or try abbrvnat or unsrtnat or plainnat
\bibliography{biblio}

\end{document}